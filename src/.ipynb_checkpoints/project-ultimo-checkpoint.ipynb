{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c917f496-e9b4-4fb8-97ca-81b0e672a967",
     "showTitle": false,
     "title": ""
    },
    "id": "WRVr5-MqggZ-"
   },
   "source": [
    "# Video Game Playability Analysis Based on Players’ Reviews with PySpark\n",
    "\n",
    "## Big Data Computing final project - A.Y. 2022-2023\n",
    "\n",
    "Prof. Gabriele Tolomei\n",
    "\n",
    "MSc in Computer Science\n",
    "\n",
    "La Sapienza, University of Rome\n",
    "\n",
    "### Author\n",
    "\n",
    "Ilaria De Sio - [desio.2064970@studenti.uniroma1.it](mailto:desio.2064970@studenti.uniroma1.it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c9c61d08-6af9-4265-8dfc-8082bb9e4ae8",
     "showTitle": false,
     "title": ""
    },
    "id": "gSMieUC0ggaB"
   },
   "source": [
    "The project is based on the paper entitled *A Data-Driven Approach for Video Game\n",
    "Playability Analysis Based on Players’ Reviews* in this case study, the definition of\n",
    "playability analyzed consists of three basic concepts ”**functionality**, **usability**, and\n",
    "**gameplay**” defined by the *framework of Paavilainen*.\n",
    "\n",
    "The goal is to obtain an explicit\n",
    "and simplified framework so that not only the intuitively quantified assessment of the\n",
    "overall playability of the chosen game is obtained but also to analyze and be able\n",
    "to view the positive and negative aspects of it, and while classifying the information\n",
    "that can be ”playability-informative” and ”non-playability-informative” divided into\n",
    "the classes listed above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "81a78200-eeac-4e26-9afa-cb556751b238",
     "showTitle": false,
     "title": ""
    },
    "id": "mw8uGOrDggaB"
   },
   "source": [
    "## Define some global constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T10:59:41.841548Z",
     "start_time": "2023-06-21T10:59:41.824730Z"
    },
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7c02dea2-d3da-4f60-a576-1d63e49a11e0",
     "showTitle": false,
     "title": ""
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1687342544058,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "0Qvq62hYggaC"
   },
   "outputs": [],
   "source": [
    "PATH=\"/Users/ilariadesio/Desktop/Computerscience/Firstyear/Secondsemester/BigData/Projects/Video_Game_Playability_Analysis/input/data_clean.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c8ba324d-2cdc-4c80-9a1a-afbfd5939212",
     "showTitle": false,
     "title": ""
    },
    "id": "ENWZUOLQggaE"
   },
   "source": [
    "## Import PySpark packages and other dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T11:00:00.115129Z",
     "start_time": "2023-06-21T10:59:41.852425Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60612,
     "status": "ok",
     "timestamp": 1687342604667,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "Gh2ZI4qzjvTS",
    "outputId": "22b1a895-e252-4699-fe89-16a63da9aa10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Users/ilariadesio/opt/anaconda3/lib/python3.9/site-packages (3.3.0)\r\n",
      "Requirement already satisfied: py4j==0.10.9.5 in /Users/ilariadesio/opt/anaconda3/lib/python3.9/site-packages (from pyspark) (0.10.9.5)\r\n",
      "Requirement already satisfied: sparknlp in /Users/ilariadesio/opt/anaconda3/lib/python3.9/site-packages (1.0.0)\r\n",
      "Requirement already satisfied: spark-nlp in /Users/ilariadesio/opt/anaconda3/lib/python3.9/site-packages (from sparknlp) (4.3.2)\r\n",
      "Requirement already satisfied: numpy in /Users/ilariadesio/opt/anaconda3/lib/python3.9/site-packages (from sparknlp) (1.21.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install sparknlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T11:00:01.963932Z",
     "start_time": "2023-06-21T11:00:00.123113Z"
    },
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3ad2abf6-dae0-492a-ae76-bf3074217bd3",
     "showTitle": false,
     "title": ""
    },
    "executionInfo": {
     "elapsed": 2676,
     "status": "ok",
     "timestamp": 1687342607338,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "Un5u3ObQggaE"
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk import *\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T11:00:04.916532Z",
     "start_time": "2023-06-21T11:00:01.968973Z"
    },
    "executionInfo": {
     "elapsed": 12100,
     "status": "ok",
     "timestamp": 1687342619434,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "6jnX0f-jHyfX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/21 13:00:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Create the session\n",
    "conf = SparkConf().\\\n",
    "                set('spark.ui.port', \"4050\").\\\n",
    "                set('spark.executor.memory', '4G').\\\n",
    "                set('spark.driver.memory', '45G').\\\n",
    "                set('spark.driver.maxResultSize', '10G').\\\n",
    "                setAppName(\"ProjectBigData\").\\\n",
    "                setMaster(\"local[*]\")\n",
    "\n",
    "# Create the context\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "50e546d7-be32-44d2-bb03-b9012ae7322a",
     "showTitle": false,
     "title": ""
    },
    "id": "Hr5wlq6mggaF"
   },
   "source": [
    "## 1.  Dataset initialization\n",
    "I chose to use the dataset [https://doi.org/10.6084/m9.figshare.14222531.v1](https://doi.org/10.6084/m9.figshare.14222531.v1) directly provided by the authors of the paper containing the review data from Steam for **No Man’s Sky** in terms of playability by users.\n",
    "This case of study is really interesting because this game was released on 2016, before which a social media “hype” had been evoked leading to an unprecedentedly high expectation.\n",
    "Unexpectedly the release was disastrous, but for the last four years, the\n",
    "game has been continuously maintained with its quality gradually increasing, which makes it a unique case where the changes in game quality is observable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T11:00:08.829524Z",
     "start_time": "2023-06-21T11:00:04.920762Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17081,
     "status": "ok",
     "timestamp": 1687342636509,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "G8sr_VdgI-5i",
    "outputId": "51d73c12-77c3-40ed-ce3b-b9dcca2f1435"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "game_dataset = spark.read.load(PATH,\n",
    "                               format=\"csv\",\n",
    "                               sep=\",\",\n",
    "                               inferSchema=\"true\",\n",
    "                               header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T11:00:10.149500Z",
     "start_time": "2023-06-21T11:00:08.833355Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 709
    },
    "executionInfo": {
     "elapsed": 5295,
     "status": "ok",
     "timestamp": 1687342641800,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "2f8S4zKMJMgr",
    "outputId": "78e35fe5-87f5-44b8-e382-541b13c33f16"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommendationid</th>\n",
       "      <th>language</th>\n",
       "      <th>review</th>\n",
       "      <th>timestamp_created</th>\n",
       "      <th>timestamp_updated</th>\n",
       "      <th>voted_up</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>weighted_vote_score</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>steam_purchase</th>\n",
       "      <th>received_for_free</th>\n",
       "      <th>written_during_early_access</th>\n",
       "      <th>author_num_games_owned</th>\n",
       "      <th>author_num_reviews</th>\n",
       "      <th>author_playtime_forever</th>\n",
       "      <th>author_playtime_last_two_weeks</th>\n",
       "      <th>author_last_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70427607</td>\n",
       "      <td>english</td>\n",
       "      <td>This game has the elements of many games sewn ...</td>\n",
       "      <td>2020-06-07 07:33:21</td>\n",
       "      <td>2020-06-07 07:33:21</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>14368</td>\n",
       "      <td>1041</td>\n",
       "      <td>2020-06-02 07:05:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70426209</td>\n",
       "      <td>english</td>\n",
       "      <td>game is k. random gen from presets. no voice a...</td>\n",
       "      <td>2020-06-07 06:48:46</td>\n",
       "      <td>2020-06-07 06:48:46</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>133</td>\n",
       "      <td>5</td>\n",
       "      <td>3927</td>\n",
       "      <td>51</td>\n",
       "      <td>2020-06-02 11:31:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70425814</td>\n",
       "      <td>english</td>\n",
       "      <td>I first played 2 years ago and it was fun for ...</td>\n",
       "      <td>2020-06-07 06:35:34</td>\n",
       "      <td>2020-06-07 06:35:34</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>670</td>\n",
       "      <td>31</td>\n",
       "      <td>1942</td>\n",
       "      <td>987</td>\n",
       "      <td>2020-06-07 06:21:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70425169</td>\n",
       "      <td>english</td>\n",
       "      <td>I wasn't sure if I'd like this--survival stuff...</td>\n",
       "      <td>2020-06-07 06:13:16</td>\n",
       "      <td>2020-06-07 06:13:16</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>98</td>\n",
       "      <td>37</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "      <td>2020-06-07 01:31:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70425032</td>\n",
       "      <td>english</td>\n",
       "      <td>This is an amazing game, Where to start?\\r\\nYo...</td>\n",
       "      <td>2020-06-07 06:08:28</td>\n",
       "      <td>2020-06-07 06:08:28</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>5887</td>\n",
       "      <td>5887</td>\n",
       "      <td>2020-06-07 07:18:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recommendationid language  \\\n",
       "0          70427607  english   \n",
       "1          70426209  english   \n",
       "2          70425814  english   \n",
       "3          70425169  english   \n",
       "4          70425032  english   \n",
       "\n",
       "                                              review    timestamp_created  \\\n",
       "0  This game has the elements of many games sewn ...  2020-06-07 07:33:21   \n",
       "1  game is k. random gen from presets. no voice a...  2020-06-07 06:48:46   \n",
       "2  I first played 2 years ago and it was fun for ...  2020-06-07 06:35:34   \n",
       "3  I wasn't sure if I'd like this--survival stuff...  2020-06-07 06:13:16   \n",
       "4  This is an amazing game, Where to start?\\r\\nYo...  2020-06-07 06:08:28   \n",
       "\n",
       "     timestamp_updated  voted_up  votes_up  votes_funny  weighted_vote_score  \\\n",
       "0  2020-06-07 07:33:21      True         0            0                  0.0   \n",
       "1  2020-06-07 06:48:46      True         0            0                  0.0   \n",
       "2  2020-06-07 06:35:34      True         0            0                  0.0   \n",
       "3  2020-06-07 06:13:16      True         0            0                  0.0   \n",
       "4  2020-06-07 06:08:28      True         0            0                  0.0   \n",
       "\n",
       "   comment_count  steam_purchase  received_for_free  \\\n",
       "0              0           False              False   \n",
       "1              0           False              False   \n",
       "2              0            True              False   \n",
       "3              0           False              False   \n",
       "4              0            True              False   \n",
       "\n",
       "   written_during_early_access  author_num_games_owned  author_num_reviews  \\\n",
       "0                        False                     143                   1   \n",
       "1                        False                     133                   5   \n",
       "2                        False                     670                  31   \n",
       "3                        False                      98                  37   \n",
       "4                        False                      16                   6   \n",
       "\n",
       "   author_playtime_forever  author_playtime_last_two_weeks  \\\n",
       "0                    14368                            1041   \n",
       "1                     3927                              51   \n",
       "2                     1942                             987   \n",
       "3                      121                             121   \n",
       "4                     5887                            5887   \n",
       "\n",
       "    author_last_played  \n",
       "0  2020-06-02 07:05:32  \n",
       "1  2020-06-02 11:31:12  \n",
       "2  2020-06-07 06:21:38  \n",
       "3  2020-06-07 01:31:17  \n",
       "4  2020-06-07 07:18:45  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_dataset=pd.read_csv(\"/Users/ilariadesio/Desktop/Computerscience/Firstyear/Secondsemester/BigData/Projects/Video_Game_Playability_Analysis/input/data_clean.csv\")\n",
    "game_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b2bbccd4-93b8-4565-9670-16ad7820d01a",
     "showTitle": false,
     "title": ""
    },
    "id": "CTT3vraEggaF"
   },
   "source": [
    "## 1.1 Dataset Shape and Scheme\n",
    "\n",
    "The dataset contains approximately 99k records of Steam's reviews.\n",
    "\n",
    "\n",
    "* ```recommendationid```: The review ID;\n",
    "* ```language```: Review language;\n",
    "* ```review```: The text of user review;\n",
    "* ```timestamp_created ```: The date a review is posted;\n",
    "* ```timestamp_updated```: Update date of a review;\n",
    "* ```voted_up```: True means it was a positive recommendation;\n",
    "* ```votes_up```: The number of other users who found this review helpful;\n",
    "* ```votes_funny```: How many other player think the review is funny;\n",
    "* ```weighted_cote_score```: Helpfulness score;\n",
    "* ```comment_count```: How many other player comment the review;\n",
    "* ```steam_purchase```: Game purchased on steam or not;\n",
    "* ```received_for_free```: Game received for free or not;\n",
    "* ```written_during_early_access```:\n",
    "* ```author_num_games_owned```: Number of games owned by the author;\n",
    "* ```author_num_reviews```: How many other reviews has this user done;\n",
    "* ```author_playtime_forever```: Number of total hours played by the author;\n",
    "* ```author_playtime_last_two_weeks```: Number of hours played by the author in the last two weeks;\n",
    "* ```author_last_played```:\n",
    "\n",
    "-------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66QN3feK8nE9"
   },
   "source": [
    "Initially in this more visual phase the dataframe provided by pandas will be used, later in text processing and for the rest of the project it will fall back to the spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T11:00:14.157419Z",
     "start_time": "2023-06-21T11:00:14.140175Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1687342641800,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "HqHrstZdJdO_",
    "outputId": "25fcc6ec-2b0a-48c8-de28-464c53fe1efd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(game_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2DcATuHj3wl"
   },
   "source": [
    "## 2. Data Pre-processing\n",
    "In this phase involves cleaning and transforming the raw data to ensure its quality and compatibility with the analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T11:00:15.148530Z",
     "start_time": "2023-06-21T11:00:15.142303Z"
    },
    "executionInfo": {
     "elapsed": 483,
     "status": "ok",
     "timestamp": 1687342642278,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "LltlOirg6xzB"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrLlA6yhAuYF"
   },
   "source": [
    "## 2.1 Data Cleaning\n",
    "\n",
    "From the data info above, we can already notice that there are missing values in review. Since our work is going to be heavily relying on this column, we have to clean it from these missing values. In addition, we also need to check for duplicated values following the standard data cleaning procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T11:00:16.226971Z",
     "start_time": "2023-06-21T11:00:16.124608Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1687342642279,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "KxRyJ1FkYyCL",
    "outputId": "e0265f2d-647f-4cde-a425-4ba3174b621a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommendationid</th>\n",
       "      <th>language</th>\n",
       "      <th>review</th>\n",
       "      <th>timestamp_created</th>\n",
       "      <th>timestamp_updated</th>\n",
       "      <th>voted_up</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>weighted_vote_score</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>steam_purchase</th>\n",
       "      <th>received_for_free</th>\n",
       "      <th>written_during_early_access</th>\n",
       "      <th>author_num_games_owned</th>\n",
       "      <th>author_num_reviews</th>\n",
       "      <th>author_playtime_forever</th>\n",
       "      <th>author_playtime_last_two_weeks</th>\n",
       "      <th>author_last_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5115</th>\n",
       "      <td>66456723</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-02 22:35:41</td>\n",
       "      <td>2020-04-02 22:35:41</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>28002</td>\n",
       "      <td>4295</td>\n",
       "      <td>2020-06-07 06:16:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>66346015</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-01 14:17:30</td>\n",
       "      <td>2020-04-01 14:17:30</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>318</td>\n",
       "      <td>3</td>\n",
       "      <td>9758</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-30 03:09:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5232</th>\n",
       "      <td>66276955</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-31 18:23:38</td>\n",
       "      <td>2020-03-31 18:23:38</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "      <td>6001</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-31 18:45:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5541</th>\n",
       "      <td>65678049</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-24 03:33:57</td>\n",
       "      <td>2020-03-24 03:33:57</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>240</td>\n",
       "      <td>5</td>\n",
       "      <td>8316</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-26 03:39:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5636</th>\n",
       "      <td>65449433</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-21 05:37:26</td>\n",
       "      <td>2020-03-21 05:37:26</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>109</td>\n",
       "      <td>6</td>\n",
       "      <td>601</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-21 16:45:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5865</th>\n",
       "      <td>65060556</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-15 02:27:56</td>\n",
       "      <td>2020-03-15 02:27:56</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>1292</td>\n",
       "      <td>74</td>\n",
       "      <td>2020-05-26 20:24:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6190</th>\n",
       "      <td>64664205</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-07 18:10:21</td>\n",
       "      <td>2020-03-07 18:10:21</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>4114</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-17 19:50:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6618</th>\n",
       "      <td>64241196</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-28 12:35:57</td>\n",
       "      <td>2020-02-28 12:35:57</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.525862</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>3288</td>\n",
       "      <td>46</td>\n",
       "      <td>2020-06-03 23:05:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6675</th>\n",
       "      <td>64210477</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-27 20:27:52</td>\n",
       "      <td>2020-02-27 20:27:52</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>5675</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-09 01:00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6840</th>\n",
       "      <td>64111598</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-25 19:02:33</td>\n",
       "      <td>2020-02-25 19:02:33</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>57</td>\n",
       "      <td>11</td>\n",
       "      <td>6720</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-20 15:29:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6852</th>\n",
       "      <td>64104298</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-25 15:57:28</td>\n",
       "      <td>2020-02-25 15:57:28</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>262</td>\n",
       "      <td>29</td>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-08 23:07:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7156</th>\n",
       "      <td>63937757</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-22 15:03:11</td>\n",
       "      <td>2020-02-22 15:03:11</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>981</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-17 00:23:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7580</th>\n",
       "      <td>63744701</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-18 22:30:32</td>\n",
       "      <td>2020-02-18 22:30:32</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>5496</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-18 15:10:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7862</th>\n",
       "      <td>63364194</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-12 01:50:53</td>\n",
       "      <td>2020-02-12 01:50:53</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>3578</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-28 19:05:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8421</th>\n",
       "      <td>62754826</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-31 20:41:51</td>\n",
       "      <td>2020-01-31 20:41:51</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>15018</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-20 02:07:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8941</th>\n",
       "      <td>62323655</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-24 13:12:01</td>\n",
       "      <td>2020-01-24 13:12:01</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>5476</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-30 09:04:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9367</th>\n",
       "      <td>61983995</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-17 16:03:25</td>\n",
       "      <td>2020-01-17 16:03:25</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>2079</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-17 18:48:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9414</th>\n",
       "      <td>61943433</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-16 18:19:43</td>\n",
       "      <td>2020-01-16 18:19:43</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.507705</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>61</td>\n",
       "      <td>9</td>\n",
       "      <td>1487</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-16 22:17:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9819</th>\n",
       "      <td>61713790</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-12 00:17:32</td>\n",
       "      <td>2020-01-12 00:17:32</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.496183</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>10803</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-18 14:16:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10051</th>\n",
       "      <td>61609227</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-10 05:55:24</td>\n",
       "      <td>2020-01-10 05:55:24</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>103</td>\n",
       "      <td>5</td>\n",
       "      <td>1125</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-28 23:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10279</th>\n",
       "      <td>61521291</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-08 13:03:26</td>\n",
       "      <td>2020-01-08 13:03:26</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1490</td>\n",
       "      <td>44</td>\n",
       "      <td>822</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-08-20 14:26:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10618</th>\n",
       "      <td>61111457</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-02 04:02:41</td>\n",
       "      <td>2020-01-02 04:02:41</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>975</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-18 16:58:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10817</th>\n",
       "      <td>60911793</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-30 13:26:09</td>\n",
       "      <td>2019-12-30 13:26:09</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.473807</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>518</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-06-03 22:22:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11573</th>\n",
       "      <td>59978107</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-16 21:30:28</td>\n",
       "      <td>2019-12-16 21:30:28</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1431</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-26 17:17:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11962</th>\n",
       "      <td>59566665</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-09 17:38:08</td>\n",
       "      <td>2019-12-09 17:38:08</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>156</td>\n",
       "      <td>13</td>\n",
       "      <td>3259</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-16 00:55:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11974</th>\n",
       "      <td>59546429</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-09 09:00:38</td>\n",
       "      <td>2019-12-09 09:00:38</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>7076</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-23 09:53:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12063</th>\n",
       "      <td>59499051</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-08 14:25:40</td>\n",
       "      <td>2019-12-08 14:25:40</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>48</td>\n",
       "      <td>17</td>\n",
       "      <td>3150</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-13 20:16:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12371</th>\n",
       "      <td>59191820</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-04 04:08:03</td>\n",
       "      <td>2019-12-04 04:08:03</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.502488</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>1555</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-16 06:18:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13012</th>\n",
       "      <td>58884016</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-01 11:47:44</td>\n",
       "      <td>2019-12-01 11:47:44</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>178</td>\n",
       "      <td>3</td>\n",
       "      <td>9009</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-01 11:46:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>58777073</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-30 17:54:37</td>\n",
       "      <td>2019-11-30 17:54:37</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16221</td>\n",
       "      <td>124</td>\n",
       "      <td>2020-06-06 19:40:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13399</th>\n",
       "      <td>58680805</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-30 05:18:28</td>\n",
       "      <td>2019-11-30 05:18:28</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>9778</td>\n",
       "      <td>39</td>\n",
       "      <td>2020-06-06 20:56:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14665</th>\n",
       "      <td>57610751</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-22 02:00:19</td>\n",
       "      <td>2019-11-22 02:00:19</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>3753</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-11-22 05:37:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14807</th>\n",
       "      <td>57284493</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-16 12:58:19</td>\n",
       "      <td>2019-11-16 12:58:19</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>14</td>\n",
       "      <td>6655</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-22 20:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15156</th>\n",
       "      <td>56635137</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-06 15:37:18</td>\n",
       "      <td>2019-11-06 15:37:18</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1711</td>\n",
       "      <td>51</td>\n",
       "      <td>1410</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-11-30 19:40:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15208</th>\n",
       "      <td>56539087</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-05 06:39:50</td>\n",
       "      <td>2019-11-05 06:39:50</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.482456</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>4189</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-03 04:38:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35370</th>\n",
       "      <td>43756176</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-07-26 12:05:11</td>\n",
       "      <td>2020-02-20 13:27:18</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1033</td>\n",
       "      <td>43</td>\n",
       "      <td>944</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-07 10:53:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       recommendationid language review    timestamp_created  \\\n",
       "5115           66456723  english    NaN  2020-04-02 22:35:41   \n",
       "5191           66346015  english    NaN  2020-04-01 14:17:30   \n",
       "5232           66276955  english    NaN  2020-03-31 18:23:38   \n",
       "5541           65678049  english    NaN  2020-03-24 03:33:57   \n",
       "5636           65449433  english    NaN  2020-03-21 05:37:26   \n",
       "5865           65060556  english    NaN  2020-03-15 02:27:56   \n",
       "6190           64664205  english    NaN  2020-03-07 18:10:21   \n",
       "6618           64241196  english    NaN  2020-02-28 12:35:57   \n",
       "6675           64210477  english    NaN  2020-02-27 20:27:52   \n",
       "6840           64111598  english    NaN  2020-02-25 19:02:33   \n",
       "6852           64104298  english    NaN  2020-02-25 15:57:28   \n",
       "7156           63937757  english    NaN  2020-02-22 15:03:11   \n",
       "7580           63744701  english    NaN  2020-02-18 22:30:32   \n",
       "7862           63364194  english    NaN  2020-02-12 01:50:53   \n",
       "8421           62754826  english    NaN  2020-01-31 20:41:51   \n",
       "8941           62323655  english    NaN  2020-01-24 13:12:01   \n",
       "9367           61983995  english    NaN  2020-01-17 16:03:25   \n",
       "9414           61943433  english    NaN  2020-01-16 18:19:43   \n",
       "9819           61713790  english    NaN  2020-01-12 00:17:32   \n",
       "10051          61609227  english    NaN  2020-01-10 05:55:24   \n",
       "10279          61521291  english    NaN  2020-01-08 13:03:26   \n",
       "10618          61111457  english    NaN  2020-01-02 04:02:41   \n",
       "10817          60911793  english    NaN  2019-12-30 13:26:09   \n",
       "11573          59978107  english    NaN  2019-12-16 21:30:28   \n",
       "11962          59566665  english    NaN  2019-12-09 17:38:08   \n",
       "11974          59546429  english    NaN  2019-12-09 09:00:38   \n",
       "12063          59499051  english    NaN  2019-12-08 14:25:40   \n",
       "12371          59191820  english    NaN  2019-12-04 04:08:03   \n",
       "13012          58884016  english    NaN  2019-12-01 11:47:44   \n",
       "13235          58777073  english    NaN  2019-11-30 17:54:37   \n",
       "13399          58680805  english    NaN  2019-11-30 05:18:28   \n",
       "14665          57610751  english    NaN  2019-11-22 02:00:19   \n",
       "14807          57284493  english    NaN  2019-11-16 12:58:19   \n",
       "15156          56635137  english    NaN  2019-11-06 15:37:18   \n",
       "15208          56539087  english    NaN  2019-11-05 06:39:50   \n",
       "35370          43756176  english    NaN  2018-07-26 12:05:11   \n",
       "\n",
       "         timestamp_updated  voted_up  votes_up  votes_funny  \\\n",
       "5115   2020-04-02 22:35:41      True         0            0   \n",
       "5191   2020-04-01 14:17:30      True         0            0   \n",
       "5232   2020-03-31 18:23:38      True         0            0   \n",
       "5541   2020-03-24 03:33:57      True         0            0   \n",
       "5636   2020-03-21 05:37:26      True         0            0   \n",
       "5865   2020-03-15 02:27:56      True         0            0   \n",
       "6190   2020-03-07 18:10:21      True         0            0   \n",
       "6618   2020-02-28 12:35:57      True         1            0   \n",
       "6675   2020-02-27 20:27:52      True         0            0   \n",
       "6840   2020-02-25 19:02:33      True         0            0   \n",
       "6852   2020-02-25 15:57:28      True         0            0   \n",
       "7156   2020-02-22 15:03:11      True         0            0   \n",
       "7580   2020-02-18 22:30:32      True         1            1   \n",
       "7862   2020-02-12 01:50:53      True         0            0   \n",
       "8421   2020-01-31 20:41:51      True         0            0   \n",
       "8941   2020-01-24 13:12:01      True         0            0   \n",
       "9367   2020-01-17 16:03:25      True         0            0   \n",
       "9414   2020-01-16 18:19:43      True         1            0   \n",
       "9819   2020-01-12 00:17:32      True         1            0   \n",
       "10051  2020-01-10 05:55:24      True         0            0   \n",
       "10279  2020-01-08 13:03:26      True         0            0   \n",
       "10618  2020-01-02 04:02:41      True         0            0   \n",
       "10817  2019-12-30 13:26:09      True         0            0   \n",
       "11573  2019-12-16 21:30:28      True         0            0   \n",
       "11962  2019-12-09 17:38:08      True         1            0   \n",
       "11974  2019-12-09 09:00:38      True         0            0   \n",
       "12063  2019-12-08 14:25:40      True         0            0   \n",
       "12371  2019-12-04 04:08:03      True         1            0   \n",
       "13012  2019-12-01 11:47:44      True         0            0   \n",
       "13235  2019-11-30 17:54:37      True         0            0   \n",
       "13399  2019-11-30 05:18:28      True         0            0   \n",
       "14665  2019-11-22 02:00:19      True         0            0   \n",
       "14807  2019-11-16 12:58:19      True         0            0   \n",
       "15156  2019-11-06 15:37:18      True         0            0   \n",
       "15208  2019-11-05 06:39:50      True         0            0   \n",
       "35370  2020-02-20 13:27:18      True         0            0   \n",
       "\n",
       "       weighted_vote_score  comment_count  steam_purchase  received_for_free  \\\n",
       "5115              0.000000              0            True              False   \n",
       "5191              0.000000              0           False              False   \n",
       "5232              0.000000              0            True              False   \n",
       "5541              0.000000              0            True              False   \n",
       "5636              0.000000              0            True              False   \n",
       "5865              0.000000              0            True              False   \n",
       "6190              0.000000              0           False              False   \n",
       "6618              0.525862              0            True              False   \n",
       "6675              0.000000              0            True              False   \n",
       "6840              0.000000              0            True              False   \n",
       "6852              0.000000              0            True              False   \n",
       "7156              0.000000              0            True              False   \n",
       "7580              0.000000              0           False              False   \n",
       "7862              0.000000              0           False              False   \n",
       "8421              0.000000              0            True              False   \n",
       "8941              0.000000              0            True              False   \n",
       "9367              0.000000              0           False              False   \n",
       "9414              0.507705              0            True              False   \n",
       "9819              0.496183              0            True              False   \n",
       "10051             0.000000              0           False              False   \n",
       "10279             0.000000              0           False              False   \n",
       "10618             0.000000              0           False              False   \n",
       "10817             0.473807              0            True              False   \n",
       "11573             0.000000              0            True              False   \n",
       "11962             0.519231              0           False               True   \n",
       "11974             0.476190              0            True              False   \n",
       "12063             0.000000              0            True              False   \n",
       "12371             0.502488              0            True              False   \n",
       "13012             0.000000              0            True              False   \n",
       "13235             0.000000              0           False              False   \n",
       "13399             0.000000              0            True              False   \n",
       "14665             0.000000              0            True              False   \n",
       "14807             0.000000              0           False              False   \n",
       "15156             0.000000              0            True              False   \n",
       "15208             0.482456              0            True              False   \n",
       "35370             0.000000              0           False              False   \n",
       "\n",
       "       written_during_early_access  author_num_games_owned  \\\n",
       "5115                         False                      29   \n",
       "5191                         False                     318   \n",
       "5232                         False                      91   \n",
       "5541                         False                     240   \n",
       "5636                         False                     109   \n",
       "5865                         False                      38   \n",
       "6190                         False                      33   \n",
       "6618                         False                      22   \n",
       "6675                         False                      58   \n",
       "6840                         False                      57   \n",
       "6852                         False                     262   \n",
       "7156                         False                      15   \n",
       "7580                         False                     120   \n",
       "7862                         False                      73   \n",
       "8421                         False                      20   \n",
       "8941                         False                      34   \n",
       "9367                         False                      91   \n",
       "9414                         False                      61   \n",
       "9819                         False                      51   \n",
       "10051                        False                     103   \n",
       "10279                        False                    1490   \n",
       "10618                        False                      26   \n",
       "10817                        False                      48   \n",
       "11573                        False                       6   \n",
       "11962                        False                     156   \n",
       "11974                        False                     102   \n",
       "12063                        False                      48   \n",
       "12371                        False                      72   \n",
       "13012                        False                     178   \n",
       "13235                        False                      44   \n",
       "13399                        False                      31   \n",
       "14665                        False                      67   \n",
       "14807                        False                     200   \n",
       "15156                        False                    1711   \n",
       "15208                        False                      32   \n",
       "35370                        False                    1033   \n",
       "\n",
       "       author_num_reviews  author_playtime_forever  \\\n",
       "5115                    1                    28002   \n",
       "5191                    3                     9758   \n",
       "5232                    3                     6001   \n",
       "5541                    5                     8316   \n",
       "5636                    6                      601   \n",
       "5865                    3                     1292   \n",
       "6190                    2                     4114   \n",
       "6618                    1                     3288   \n",
       "6675                    1                     5675   \n",
       "6840                   11                     6720   \n",
       "6852                   29                     1309   \n",
       "7156                    1                      981   \n",
       "7580                    3                     5496   \n",
       "7862                    2                     3578   \n",
       "8421                    2                    15018   \n",
       "8941                    8                     5476   \n",
       "9367                    1                     2079   \n",
       "9414                    9                     1487   \n",
       "9819                    6                    10803   \n",
       "10051                   5                     1125   \n",
       "10279                  44                      822   \n",
       "10618                   3                      975   \n",
       "10817                   6                      518   \n",
       "11573                   4                     1431   \n",
       "11962                  13                     3259   \n",
       "11974                   2                     7076   \n",
       "12063                  17                     3150   \n",
       "12371                   3                     1555   \n",
       "13012                   3                     9009   \n",
       "13235                   1                    16221   \n",
       "13399                   1                     9778   \n",
       "14665                   5                     3753   \n",
       "14807                  14                     6655   \n",
       "15156                  51                     1410   \n",
       "15208                   3                     4189   \n",
       "35370                  43                      944   \n",
       "\n",
       "       author_playtime_last_two_weeks   author_last_played  \n",
       "5115                             4295  2020-06-07 06:16:39  \n",
       "5191                                0  2020-04-30 03:09:27  \n",
       "5232                                0  2020-03-31 18:45:40  \n",
       "5541                                0  2020-04-26 03:39:39  \n",
       "5636                                0  2020-03-21 16:45:18  \n",
       "5865                               74  2020-05-26 20:24:50  \n",
       "6190                                0  2020-03-17 19:50:32  \n",
       "6618                               46  2020-06-03 23:05:22  \n",
       "6675                                0  2020-04-09 01:00:06  \n",
       "6840                                0  2020-04-20 15:29:47  \n",
       "6852                                0  2020-04-08 23:07:03  \n",
       "7156                                0  2020-05-17 00:23:30  \n",
       "7580                                0  2020-05-18 15:10:14  \n",
       "7862                                0  2020-03-28 19:05:17  \n",
       "8421                                0  2020-05-20 02:07:34  \n",
       "8941                                0  2020-01-30 09:04:10  \n",
       "9367                                0  2020-01-17 18:48:13  \n",
       "9414                                0  2020-01-16 22:17:09  \n",
       "9819                                0  2020-04-18 14:16:39  \n",
       "10051                               0  2020-01-28 23:43:10  \n",
       "10279                               0  2019-08-20 14:26:57  \n",
       "10618                               0  2020-01-18 16:58:52  \n",
       "10817                               1  2020-06-03 22:22:32  \n",
       "11573                               0  2020-03-26 17:17:49  \n",
       "11962                               0  2020-03-16 00:55:27  \n",
       "11974                               0  2020-01-23 09:53:02  \n",
       "12063                               0  2019-12-13 20:16:53  \n",
       "12371                               0  2019-12-16 06:18:07  \n",
       "13012                               0  2019-12-01 11:46:24  \n",
       "13235                             124  2020-06-06 19:40:56  \n",
       "13399                              39  2020-06-06 20:56:57  \n",
       "14665                               0  2019-11-22 05:37:18  \n",
       "14807                               0  2020-02-22 20:43:15  \n",
       "15156                               0  2019-11-30 19:40:05  \n",
       "15208                               0  2019-12-03 04:38:51  \n",
       "35370                               0  2020-03-07 10:53:58  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_dataset[game_dataset['review'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T11:00:16.511542Z",
     "start_time": "2023-06-21T11:00:16.403637Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 400,
     "status": "ok",
     "timestamp": 1687342642674,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "k1CJGmLVZNKB",
    "outputId": "99994245-6095-4e1d-e25e-5892b012ae84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recommendationid                   0\n",
       "language                           0\n",
       "review                            36\n",
       "timestamp_created                  0\n",
       "timestamp_updated                  0\n",
       "voted_up                           0\n",
       "votes_up                           0\n",
       "votes_funny                        0\n",
       "weighted_vote_score                0\n",
       "comment_count                      0\n",
       "steam_purchase                     0\n",
       "received_for_free                  0\n",
       "written_during_early_access        0\n",
       "author_num_games_owned             0\n",
       "author_num_reviews                 0\n",
       "author_playtime_forever            0\n",
       "author_playtime_last_two_weeks     0\n",
       "author_last_played                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T11:00:17.409247Z",
     "start_time": "2023-06-21T11:00:16.955184Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 798,
     "status": "ok",
     "timestamp": 1687342643470,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "iZN5xnLEZqnm",
    "outputId": "ed0f850c-e80f-4825-f0e1-86e3d090449d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recommendationid                  0\n",
       "language                          0\n",
       "review                            0\n",
       "timestamp_created                 0\n",
       "timestamp_updated                 0\n",
       "voted_up                          0\n",
       "votes_up                          0\n",
       "votes_funny                       0\n",
       "weighted_vote_score               0\n",
       "comment_count                     0\n",
       "steam_purchase                    0\n",
       "received_for_free                 0\n",
       "written_during_early_access       0\n",
       "author_num_games_owned            0\n",
       "author_num_reviews                0\n",
       "author_playtime_forever           0\n",
       "author_playtime_last_two_weeks    0\n",
       "author_last_played                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with missing reviews\n",
    "game_dataset.dropna(inplace=True)\n",
    "\n",
    "# Sanity check\n",
    "game_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T11:00:17.678509Z",
     "start_time": "2023-06-21T11:00:17.585407Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1687342643700,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "cdatonw6xuuQ",
    "outputId": "6b8fb761-afbb-46f5-8662-6ad47e741edd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recommendationid                  99957\n",
       "language                          99957\n",
       "review                            99957\n",
       "timestamp_created                 99957\n",
       "timestamp_updated                 99957\n",
       "voted_up                          99957\n",
       "votes_up                          99957\n",
       "votes_funny                       99957\n",
       "weighted_vote_score               99957\n",
       "comment_count                     99957\n",
       "steam_purchase                    99957\n",
       "received_for_free                 99957\n",
       "written_during_early_access       99957\n",
       "author_num_games_owned            99957\n",
       "author_num_reviews                99957\n",
       "author_playtime_forever           99957\n",
       "author_playtime_last_two_weeks    99957\n",
       "author_last_played                99957\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_dataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VydHh8Z8x2RI"
   },
   "source": [
    "Rows with null values have been deleted correctly, now the rows are 99957.\n",
    "Now let's check for duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T11:00:19.585489Z",
     "start_time": "2023-06-21T11:00:18.863509Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1687342643974,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "sqxXm1V4Z1vz",
    "outputId": "f34587c0-322b-468e-88d7-59d3f0f28823"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVAT5Q2EaNFD"
   },
   "source": [
    "It seems that there are no duplicated rows. But are there duplicated reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T11:00:20.555210Z",
     "start_time": "2023-06-21T11:00:20.294301Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1687342644234,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "bOhB4w3zaO4e",
    "outputId": "759e1f35-665e-4075-c2d1-f42a3c65d1dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3903"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_dataset.duplicated(subset='review').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T11:00:20.997483Z",
     "start_time": "2023-06-21T11:00:20.767408Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1687342644235,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "J562ceGbafCC",
    "outputId": "5d08809f-fd52-4025-a6ae-ba630f307ff2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommendationid</th>\n",
       "      <th>language</th>\n",
       "      <th>review</th>\n",
       "      <th>timestamp_created</th>\n",
       "      <th>timestamp_updated</th>\n",
       "      <th>voted_up</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>weighted_vote_score</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>steam_purchase</th>\n",
       "      <th>received_for_free</th>\n",
       "      <th>written_during_early_access</th>\n",
       "      <th>author_num_games_owned</th>\n",
       "      <th>author_num_reviews</th>\n",
       "      <th>author_playtime_forever</th>\n",
       "      <th>author_playtime_last_two_weeks</th>\n",
       "      <th>author_last_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52209</th>\n",
       "      <td>26126311</td>\n",
       "      <td>english</td>\n",
       "      <td>No.</td>\n",
       "      <td>2016-10-20 08:06:52</td>\n",
       "      <td>2016-10-20 08:06:52</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>189</td>\n",
       "      <td>4</td>\n",
       "      <td>9832</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-25 06:04:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49222</th>\n",
       "      <td>27763203</td>\n",
       "      <td>english</td>\n",
       "      <td>Lies</td>\n",
       "      <td>2016-11-27 02:31:41</td>\n",
       "      <td>2016-11-27 02:31:41</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.489150</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>831</td>\n",
       "      <td>5</td>\n",
       "      <td>8943</td>\n",
       "      <td>48</td>\n",
       "      <td>2020-06-05 18:39:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54350</th>\n",
       "      <td>25872674</td>\n",
       "      <td>english</td>\n",
       "      <td>No Man's Lie.</td>\n",
       "      <td>2016-10-05 17:35:07</td>\n",
       "      <td>2016-10-05 17:35:07</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.490232</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>499</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-15 01:54:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48813</th>\n",
       "      <td>27913543</td>\n",
       "      <td>english</td>\n",
       "      <td>It's getting there</td>\n",
       "      <td>2016-11-28 03:56:40</td>\n",
       "      <td>2016-11-28 03:56:40</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.504201</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>345</td>\n",
       "      <td>7</td>\n",
       "      <td>4322</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-08 18:08:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51744</th>\n",
       "      <td>26242149</td>\n",
       "      <td>english</td>\n",
       "      <td>Just no.</td>\n",
       "      <td>2016-10-27 07:57:24</td>\n",
       "      <td>2016-10-27 07:57:24</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481752</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>938</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-05-09 12:48:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74128</th>\n",
       "      <td>24996583</td>\n",
       "      <td>english</td>\n",
       "      <td>.</td>\n",
       "      <td>2016-08-18 17:42:03</td>\n",
       "      <td>2016-08-18 17:42:03</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.411442</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>7709</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-25 16:16:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>67336813</td>\n",
       "      <td>english</td>\n",
       "      <td>DO IT.</td>\n",
       "      <td>2020-04-15 02:54:39</td>\n",
       "      <td>2020-04-15 02:54:39</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>9172</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-05 16:58:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26999</th>\n",
       "      <td>46077908</td>\n",
       "      <td>english</td>\n",
       "      <td>Good</td>\n",
       "      <td>2018-11-21 23:20:09</td>\n",
       "      <td>2018-11-21 23:20:09</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>7109</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-25 15:34:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60210</th>\n",
       "      <td>25274215</td>\n",
       "      <td>english</td>\n",
       "      <td>Terrible</td>\n",
       "      <td>2016-08-31 19:43:26</td>\n",
       "      <td>2016-08-31 19:43:26</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.501744</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>164</td>\n",
       "      <td>3</td>\n",
       "      <td>1551</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-08-25 16:56:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088</th>\n",
       "      <td>60573620</td>\n",
       "      <td>english</td>\n",
       "      <td>fun with friends</td>\n",
       "      <td>2019-12-26 05:35:53</td>\n",
       "      <td>2019-12-26 05:35:53</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>54</td>\n",
       "      <td>19</td>\n",
       "      <td>1570</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-19 22:32:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       recommendationid language              review    timestamp_created  \\\n",
       "52209          26126311  english                 No.  2016-10-20 08:06:52   \n",
       "49222          27763203  english                Lies  2016-11-27 02:31:41   \n",
       "54350          25872674  english       No Man's Lie.  2016-10-05 17:35:07   \n",
       "48813          27913543  english  It's getting there  2016-11-28 03:56:40   \n",
       "51744          26242149  english            Just no.  2016-10-27 07:57:24   \n",
       "74128          24996583  english                   .  2016-08-18 17:42:03   \n",
       "3314           67336813  english              DO IT.  2020-04-15 02:54:39   \n",
       "26999          46077908  english                Good  2018-11-21 23:20:09   \n",
       "60210          25274215  english            Terrible  2016-08-31 19:43:26   \n",
       "11088          60573620  english    fun with friends  2019-12-26 05:35:53   \n",
       "\n",
       "         timestamp_updated  voted_up  votes_up  votes_funny  \\\n",
       "52209  2016-10-20 08:06:52     False         7            0   \n",
       "49222  2016-11-27 02:31:41     False         1            0   \n",
       "54350  2016-10-05 17:35:07     False        17            1   \n",
       "48813  2016-11-28 03:56:40      True         2            0   \n",
       "51744  2016-10-27 07:57:24     False         4            0   \n",
       "74128  2016-08-18 17:42:03     False        10            1   \n",
       "3314   2020-04-15 02:54:39      True         0            0   \n",
       "26999  2018-11-21 23:20:09      True         1            0   \n",
       "60210  2016-08-31 19:43:26     False         6            0   \n",
       "11088  2019-12-26 05:35:53      True         1            0   \n",
       "\n",
       "       weighted_vote_score  comment_count  steam_purchase  received_for_free  \\\n",
       "52209             0.000000              0            True              False   \n",
       "49222             0.489150              0            True              False   \n",
       "54350             0.490232              0            True              False   \n",
       "48813             0.504201              2            True              False   \n",
       "51744             0.481752              0            True              False   \n",
       "74128             0.411442              0            True              False   \n",
       "3314              0.000000              0            True              False   \n",
       "26999             0.523810              0            True              False   \n",
       "60210             0.501744              0            True              False   \n",
       "11088             0.500000              0            True              False   \n",
       "\n",
       "       written_during_early_access  author_num_games_owned  \\\n",
       "52209                        False                     189   \n",
       "49222                        False                     831   \n",
       "54350                        False                     173   \n",
       "48813                        False                     345   \n",
       "51744                        False                      89   \n",
       "74128                        False                      30   \n",
       "3314                         False                      61   \n",
       "26999                        False                      93   \n",
       "60210                        False                     164   \n",
       "11088                        False                      54   \n",
       "\n",
       "       author_num_reviews  author_playtime_forever  \\\n",
       "52209                   4                     9832   \n",
       "49222                   5                     8943   \n",
       "54350                   1                      499   \n",
       "48813                   7                     4322   \n",
       "51744                   1                      938   \n",
       "74128                   2                     7709   \n",
       "3314                    2                     9172   \n",
       "26999                   2                     7109   \n",
       "60210                   3                     1551   \n",
       "11088                  19                     1570   \n",
       "\n",
       "       author_playtime_last_two_weeks   author_last_played  \n",
       "52209                               0  2020-02-25 06:04:30  \n",
       "49222                              48  2020-06-05 18:39:47  \n",
       "54350                               0  2016-08-15 01:54:02  \n",
       "48813                               0  2020-04-08 18:08:53  \n",
       "51744                               0  2018-05-09 12:48:10  \n",
       "74128                               0  2020-04-25 16:16:10  \n",
       "3314                                0  2020-05-05 16:58:25  \n",
       "26999                               0  2020-02-25 15:34:23  \n",
       "60210                               0  2019-08-25 16:56:48  \n",
       "11088                               0  2020-01-19 22:32:11  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_dataset[game_dataset.duplicated(subset='review',keep=False)].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_u77e_xUzj3q"
   },
   "source": [
    "As we can see there are not actually equal reviews but with similar terms, most of them are very short reviews such as 'good' or 'amazing'. These reviews are still important for our classification task, so we will not drop them.\n",
    "\n",
    "##Text-processing\n",
    "We may note that some reviews may also be written only by special characters, these types of reviews should be removed, because there may be smilies or special characters are not significant and also that may have multiple or ambiguous meanings, making accurate interpretation difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T11:00:40.266709Z",
     "start_time": "2023-06-21T11:00:23.260019Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32279,
     "status": "ok",
     "timestamp": 1687342706588,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "Oipz6aLTWAwx",
    "outputId": "7c506d48-98a5-4826-ec74-42ab876b3cf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/21 13:00:34 WARN TaskSetManager: Stage 2 contains a task of very large size (4301 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/21 13:00:40 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 2 (TID 9): Attempting to kill Python Worker\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|review                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|This game has the elements of many games sewn into one, which it does so incredibly well. A bit of survival, fps, space sim, trading, farming, base building, questing, character development and multiplayer missions. The result is a beautifully presented journey of discovery that meant 200+ hours melted away so easily.\\r\\nWould recommend to everyone who is adventurous.\\r\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "|game is k. random gen from presets. no voice acting. Gets old. but none the less was a swell time.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
      "|I first played 2 years ago and it was fun for a bit. Then I started playing again recently and its better.\\r\\n\\r\\nCriticisms:\\r\\n>  Too Many Asteroids, asteroids should be spaced better and shouldn't appear out of nowhere. The deeper into space you go the less asteroids there should be. It's just so cluttered its the least immersive part\\r\\n> It feels like a lot of stuff changes each time you load the game. Species of characters on your freighter might change all of a sudden, or a planet might be unnamed after leaving and coming back. Just weird stuff that gives you deja-vu. C'est tres confusing.\\r\\n> I have no idea what materials are gonna be important and theres not enough room on my ship or in my inventory to make sure I have everything I need. When I travel from one system to another to do a quest, and then that quest requires a material I can't find for some reason, that leads to a lot of extra travel that gets tiresome. Which is related to the issue of a planet saying it has a material on it but I cannot find a single gram of it no matter what.\\r\\n> Abandoned, crashed, sunk freighters are hard to navigate and its not clear what you're supposed to do with them. I found stuff at one before but haven't since then. Just waste my time trying to figure out what to do.\\r\\n> The anomaly hub thing where you meet other players reveals a lot about the game and progress, but I got there so early it didn't make sense since I couldn't really do anything like moon buggys or submersibles yet.\\r\\n> There are no civilisations. There are plenty of aliens and species and all that, and you can interact with people on space stations and in little structures on the surface of planets, but it doesn't feel lived in. There are no major cities or villages that I've come across yet, and no sense of REAL culture or society. So a lot of standings don't have any impact on my connection to the game.\\r\\n>> Theres just a lot of tedious stuff that takes away from the otherwise fun experience.\\r\\n\\r\\nPositives:\\r\\n+ Fairly easy to fly\\r\\n+ Fairly easy to use menus\\r\\n+ Easy to build bases\\r\\n+ Depending on your playstyle theres a lot to do. For me I am just trying to be as rich as possible so I can own a huge fleet of frigates and ships so doing trade missions and mining a bunch is fun.\\r\\n+ So many ways to customise your experience.\\r\\n+ It's like Elite Dangerous on super easy baby mode\\r\\n+ A lot of story elements based on easy to follow philosophy\\r\\n+ So far not too preachy about that philosophy\\r\\n++ So yeah just a casually fun game, not much to say though|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_df = spark.createDataFrame(game_dataset)\n",
    "spark_df.select(\"review\").show(n=3,truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kuz2qabbBVpc"
   },
   "source": [
    "###Convert all the text of the review to lowercase, Tokenization-into-sentences and Removal of extra-spaces and some special characters\n",
    "In this phase divide each review item from the DataFrame into sentence-level review instances, due to the fact that each review with multiple sentences can contain multiple topics and various sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7460,
     "status": "ok",
     "timestamp": 1687307752443,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "7wWWpAk1cMTd",
    "outputId": "663656b0-bd8c-4ea5-da6c-4648af7a6bed"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower, regexp_replace, trim\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Convert all the text of the review to lowercase\n",
    "to_lower = udf(lambda x: x.lower(), StringType())\n",
    "\n",
    "# Removal of extra-spaces and some special characters\n",
    "def clean_and_split_sentences(text):\n",
    "    cleaned_text = re.sub(r'[^\\w\\s.]', '', text)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text.strip())\n",
    "    sentences = sent_tokenize(cleaned_text)\n",
    "    return sentences\n",
    "\n",
    "spark_df = spark_df.withColumn('review', to_lower(spark_df['review']))\n",
    "\n",
    "# Apply the function to the column\n",
    "clean_and_split_udf = udf(clean_and_split_sentences, ArrayType(StringType()))\n",
    "spark_df = spark_df.withColumn('sentences', clean_and_split_udf(spark_df['review']))\n",
    "\n",
    "\n",
    "spark_df.select(\"review\",'sentences').show(n=1,truncate=False)\n",
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YKjcPjPdAgU"
   },
   "source": [
    "###Sentence Tokenization Vecchia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5490,
     "status": "ok",
     "timestamp": 1687294998795,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "KsmCp3b-BOhS",
    "outputId": "cf94c3df-548b-40f4-addd-7ae0e55eb973"
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "def sent_tokenize(text):\n",
    "    return nltk.sent_tokenize(text)\n",
    "\n",
    "# Creating the UDF function for the phrase tokenizer.\n",
    "sent_tokenize_udf = udf(sent_tokenize, ArrayType(StringType()))\n",
    "\n",
    "# Applying the phrase tokenizer to the 'review' column of the DataFrame.\n",
    "spark_df = spark_df.withColumn('sentences', sent_tokenize_udf(spark_df['review']))\n",
    "\n",
    "columns = spark_df.columns\n",
    "columns.remove('sentences')\n",
    "spark_df = spark_df.select(columns[:3] + ['sentences'] + columns[3:])\n",
    "\n",
    "first_row = spark_df.select('sentences').show(n=5, truncate=False)\n",
    "print(first_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TEiypee3sWQN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34eeT8mlsWvs"
   },
   "source": [
    "# Prove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6hNOvf70AiW"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Aggiungi una colonna chiamata 'target' con valori numerici costanti\n",
    "spark_df = spark_df.withColumn('target', lit(0.0))  # Cambia 0.0 con il valore numerico desiderato\n",
    "\n",
    "# Mostra il DataFrame risultante\n",
    "spark_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E3GW48x_-dHa"
   },
   "outputs": [],
   "source": [
    "train_df,test_df=spark_df.randomSplit([0.7,0.3],seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 106229,
     "status": "ok",
     "timestamp": 1687307867695,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "CGZ4IVlUWeTP",
    "outputId": "4ae26ef1-1bd1-4367-e879-73d2088c3863"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "# Tokenizzazione del testo delle recensioni\n",
    "tokenizer = Tokenizer(inputCol=\"review\", outputCol=\"tokenized_review\")\n",
    "spark_df = tokenizer.transform(spark_df)\n",
    "\n",
    "# Rimozione delle stopwords\n",
    "stopwords_remover = StopWordsRemover(inputCol=\"tokenized_review\", outputCol=\"clean_review\")\n",
    "spark_df = stopwords_remover.transform(spark_df)\n",
    "\n",
    "# Estrazione delle caratteristiche del testo\n",
    "count_vectorizer = CountVectorizer(inputCol=\"clean_review\", outputCol=\"features\")\n",
    "model = count_vectorizer.fit(spark_df)\n",
    "spark_df = model.transform(spark_df)\n",
    "\n",
    "# Addestramento del modello di clustering\n",
    "k = 2  # Numero di cluster desiderati\n",
    "kmeans = KMeans(featuresCol=\"features\", predictionCol=\"cluster\", k=k)\n",
    "kmeans_model = kmeans.fit(spark_df)\n",
    "\n",
    "# Previsione dei cluster per il DataFrame originale\n",
    "predicted_df = kmeans_model.transform(spark_df)\n",
    "\n",
    "# Visualizza i risultati\n",
    "predicted_df.select(\"review\", \"cluster\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 566
    },
    "executionInfo": {
     "elapsed": 31918,
     "status": "ok",
     "timestamp": 1687307903223,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "bex7vWPyXeX1",
    "outputId": "d829040f-1139-444a-e4ea-7ae96db274e1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Converti il DataFrame Spark delle previsioni dei cluster in un DataFrame Pandas\n",
    "predicted_df_pandas = predicted_df.select(\"review\", \"cluster\").toPandas()\n",
    "\n",
    "# Conta il numero di recensioni in ciascun cluster\n",
    "cluster_counts = predicted_df_pandas[\"cluster\"].value_counts()\n",
    "\n",
    "# Visualizza i cluster con un grafico a barre\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=cluster_counts.index, y=cluster_counts.values)\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Numero di recensioni\")\n",
    "plt.title(\"Distribuzione dei cluster\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GaWehUy1a-ox"
   },
   "source": [
    "# mantieni prova hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGXW-f_I6lS4"
   },
   "source": [
    "###Convert all the text of the review to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMX15z9IcRhh"
   },
   "outputs": [],
   "source": [
    "def convert_to_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "convert_to_lowercase_udf = udf(convert_to_lowercase, StringType())\n",
    "\n",
    "# Application of the UDF to the 'review' column of the DataFrame\n",
    "spark_df = spark_df.withColumn('review_lower', convert_to_lowercase_udf(spark_df['review']))\n",
    "\n",
    "\"\"\"\n",
    "Since it is not possible to directly assign the UDF result to the same input column in Spark (this is due to the fact that Spark's DataFrames are immutable,\n",
    "which means that they cannot be changed directly),\n",
    "a new column called lower_reviews will be created and then replaced with the original reviews and deleted.\n",
    "\"\"\"\n",
    "spark_df = spark_df.withColumn(spark_df.columns[2], col('review_lower'))\n",
    "spark_df=spark_df.drop('review_lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfwE40zfTKdD"
   },
   "source": [
    "##Removal of extra-spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gdA3MUisTG0f"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ojdkt09FUnSJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjZK02GF-KMg"
   },
   "source": [
    "###Removal of non-ASCII characters\n",
    "For example, the dollar sign ($), accented letters such as à, é, ô, also there are many special symbols such as ☺ (smiley face) and others that are not included in standard ASCII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4598,
     "status": "ok",
     "timestamp": 1687285081749,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "7naKQxAy-Wjq",
    "outputId": "c523ae0d-57eb-46d1-82a6-8cca49edb514"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "import re\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    # Utilizziamo un'espressione regolare per trovare tutti i caratteri non ASCII\n",
    "    non_ascii_regex = re.compile('[^\\x00-\\x7F]')\n",
    "    # Sostituiamo i caratteri non ASCII con una stringa vuota\n",
    "    cleaned_text = non_ascii_regex.sub('', text)\n",
    "    return cleaned_text\n",
    "\n",
    "# Definizione della funzione UDF (User-Defined Function)\n",
    "remove_non_ascii_udf = udf(remove_non_ascii, StringType())\n",
    "\n",
    "# Applicazione della funzione UDF alla colonna 'review'\n",
    "spark_df = spark_df.withColumn('cleaned_review', remove_non_ascii_udf(spark_df['review']))\n",
    "\n",
    "spark_df = spark_df.withColumn(spark_df.columns[2], col('cleaned_review'))\n",
    "spark_df=spark_df.drop('cleaned_review')\n",
    "\n",
    "\n",
    "first_row = spark_df.select('review').show(n=5, truncate=False)\n",
    "print(first_row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFrIr8v5wVH6"
   },
   "source": [
    "### Remove Stop-words (NOT USED by Project Choice)\n",
    "I initially tried to apply to the removal of stop words, but seeing the results, I noticed that it might result in the loss of some relevant information about sentence structure, so I decided not to use it in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mN_zvztdoz4u"
   },
   "source": [
    "## 2.2 Data Exploration\n",
    "At this phase I will analyze different hypotheses of correlation tar the variables to actually test whether or not they are correlated according to the hypothesis provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLeUlIM3rJmt"
   },
   "source": [
    "### 2.2.1 First Hypothesis\n",
    "**Does there exist a correlation between the number of hours a person played a game and the sentiment of the review?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18UwZtI8pmbu"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"vader_lexicon\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CBndJErkWj6"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Converte il DataFrame Pandas in un DataFrame PySpark\n",
    "spark_df = spark.createDataFrame(game_dataset)\n",
    "\n",
    "# Inizializza il SentimentIntensityAnalyzer di NLTK\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Definisci la funzione per l'analisi del sentiment\n",
    "def analyze_sentiment(review):\n",
    "    # Calcola il sentiment della recensione utilizzando il SentimentIntensityAnalyzer di NLTK\n",
    "    sentiment = sia.polarity_scores(review)[\"compound\"]\n",
    "\n",
    "    # Determina se la recensione è positiva o negativa in base al valore del sentiment\n",
    "    if sentiment > 0:\n",
    "        return \"positive\"\n",
    "    elif sentiment < 0:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "# Registra la funzione come UDF (User Defined Function)\n",
    "sentiment_udf = udf(analyze_sentiment, StringType())\n",
    "\n",
    "# Applica la sentiment analysis al DataFrame\n",
    "classified_df = spark_df.withColumn(\"sentiment\", sentiment_udf(spark_df[\"review\"]))\n",
    "\n",
    "# Dividi il DataFrame in due DataFrame separati per le recensioni positive e negative\n",
    "positive_reviews = classified_df.filter(classified_df[\"sentiment\"] == \"positive\")\n",
    "negative_reviews = classified_df.filter(classified_df[\"sentiment\"] == \"negative\")\n",
    "\n",
    "\n",
    "# Mostra i risultati del DataFrame positive_reviews come DataFrame Pandas\n",
    "positive_reviews_pandas = positive_reviews.toPandas().head(5)\n",
    "print(\"Positive Reviews:\")\n",
    "print(positive_reviews_pandas)\n",
    "\n",
    "# Mostra i risultati del DataFrame negative_reviews come DataFrame Pandas\n",
    "negative_reviews_pandas = negative_reviews.toPandas().head(5)\n",
    "print(\"Negative Reviews:\")\n",
    "print(negative_reviews_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEoJPC2jUlga"
   },
   "source": [
    "#WordCloud DA FARE PER PLAYABILITY INFORMATIVE E NON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 35113,
     "status": "ok",
     "timestamp": 1687290104053,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "V0TOxdEdUj5E",
    "outputId": "9ccce0d8-dbff-4771-a5e1-743ce6e5b843"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, split, col\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Split delle parole all'interno della colonna 'review'\n",
    "words = spark_df.select(explode(split(col(\"review\"), \" \")).alias(\"word\"))\n",
    "# Rimuovi le parole vuote o con lunghezza inferiore a 3\n",
    "words = words.filter((col(\"word\") != \"\") & (length(col(\"word\")) > 2))\n",
    "\n",
    "word_counts = words.groupBy(\"word\").count()\n",
    "\n",
    "wordcloud_data = word_counts.rdd.collectAsMap()\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=400, max_words=200, background_color=\"white\").generate_from_frequencies(wordcloud_data)\n",
    "\n",
    "# Plot del word cloud\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Me7LtqZluFII"
   },
   "source": [
    "# prova 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5d7C-0KduG3c"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "train_df,test_df=spark_df.randomSplit([0.7,0.3],seed=42)\n",
    "\n",
    "# Fase 2: Estrazione delle features\n",
    "tokenizer = Tokenizer(inputCol='review', outputCol='words')\n",
    "test_df = tokenizer.transform(test_df)\n",
    "\n",
    "remover = StopWordsRemover(inputCol='words', outputCol='filtered_words')\n",
    "test_df = remover.transform(test_df)\n",
    "\n",
    "vectorizer = CountVectorizer(inputCol='filtered_words', outputCol='features')\n",
    "vectorizer_model = vectorizer.fit(test_df)\n",
    "test_df = vectorizer_model.transform(test_df)\n",
    "\n",
    "# Fase 3: Riduzione della dimensionalità\n",
    "pca = PCA(k=100, inputCol='features', outputCol='pca_features')\n",
    "pca_model = pca.fit(test_df)\n",
    "test_df = pca_model.transform(test_df)\n",
    "\n",
    "# Fase 4: Clustering\n",
    "kmeans = KMeans(k=3, seed=42, featuresCol='pca_features', predictionCol='cluster')\n",
    "kmeans_model = kmeans.fit(test_df)\n",
    "test_df = kmeans_model.transform(test_df)\n",
    "\n",
    "\n",
    "# Fase 5: Analisi dei cluster e assegnazione delle etichette\n",
    "cluster_labels = {\n",
    "    0: \"Alta giocabilità\",\n",
    "    1: \"Media giocabilità\",\n",
    "    2: \"Bassa giocabilità\"\n",
    "}\n",
    "\n",
    "# Calcola le statistiche dei cluster\n",
    "cluster_stats = test_df.groupBy('cluster').count().alias('count')\n",
    "\n",
    "# Stampa le statistiche dei cluster\n",
    "cluster_stats.show()\n",
    "\n",
    "# Assegna le etichette ai cluster\n",
    "def assign_label(cluster):\n",
    "    return cluster_labels[cluster]\n",
    "\n",
    "assign_label_udf = F.udf(assign_label, StringType())\n",
    "test_df = test_df.withColumn('cluster_label', assign_label_udf('cluster'))\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Converti il dataframe Spark in un dataframe Pandas per la visualizzazione\n",
    "pandas_df = test_df.select('pca_features', 'cluster_label').toPandas()\n",
    "\n",
    "# Visualizza i cluster utilizzando un grafico a dispersione (scatter plot)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(pandas_df['pca_features'].apply(lambda x: x[0]), pandas_df['pca_features'].apply(lambda x: x[1]),\n",
    "            c=pandas_df['cluster_label'].astype('category').cat.codes, cmap='viridis')\n",
    "plt.title('Visualizzazione dei cluster')\n",
    "plt.xlabel('Componente principale 1')\n",
    "plt.ylabel('Componente principale 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "executionInfo": {
     "elapsed": 311,
     "status": "error",
     "timestamp": 1687299613522,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "bPMrPXkQ4WCk",
    "outputId": "a31ae4f8-e7b1-4976-c56c-c3edd12f47c7"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer,StopWordsRemover,CountVectorizer,IDF\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(inputCol='sentences',outputCol='rawFeatures')\n",
    "idf = IDF(inputCol='rawFeatures',outputCol='vectorizedFeatures')\n",
    "\n",
    "labelEncoder = StringIndexer(inputCol='subject',outputCol='label').fit(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZsE5DZ_duhb4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAw8-NK7ui-A"
   },
   "source": [
    "#New hypothesis\n",
    "**Does there exist a relationship between the text of the review and the number of votes up that it receives? Can we predict this value with a Machine Learning model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T11:01:05.215145Z",
     "start_time": "2023-06-21T11:01:02.177269Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9829,
     "status": "ok",
     "timestamp": 1687342720599,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "gJSliB-kwX7L",
    "outputId": "111c265e-256f-4a26-c6f6-a8222f243d50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/21 13:01:02 WARN TaskSetManager: Stage 3 contains a task of very large size (4301 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/21 13:01:04 WARN TaskSetManager: Stage 6 contains a task of very large size (4301 KiB). The maximum recommended task size is 1000 KiB.\n",
      "Valore minimo: 0\n",
      "Valore massimo: 16993\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calcola il valore minimo e massimo della colonna desiderata\n",
    "min_value = spark_df.agg(min(spark_df['votes_up'])).collect()[0][0]\n",
    "max_value = spark_df.agg(max(spark_df['votes_up'])).collect()[0][0]\n",
    "\n",
    "# Visualizza il valore minimo e massimo\n",
    "print(\"Valore minimo:\", min_value)\n",
    "print(\"Valore massimo:\", max_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T11:01:10.131004Z",
     "start_time": "2023-06-21T11:01:06.854571Z"
    },
    "executionInfo": {
     "elapsed": 5725,
     "status": "ok",
     "timestamp": 1687342727360,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "WYG9mLXsRgva"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/21 13:01:07 WARN TaskSetManager: Stage 9 contains a task of very large size (4301 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "votes_up_for_useful_review = spark_df.approxQuantile(\"votes_up\", [0.99], 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T11:01:13.424268Z",
     "start_time": "2023-06-21T11:01:10.139938Z"
    },
    "executionInfo": {
     "elapsed": 10428,
     "status": "ok",
     "timestamp": 1687342739136,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "R7FtZl3-upk8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/21 13:01:10 WARN TaskSetManager: Stage 11 contains a task of very large size (4301 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/06/21 13:01:10 WARN TaskSetManager: Stage 12 contains a task of very large size (4301 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/21 13:01:11 WARN TaskSetManager: Stage 15 contains a task of very large size (4301 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# Selezionare le colonne 'review' e 'votes_up' e limitare ai primi 5 record\n",
    "limited_df = spark_df.select('review', 'votes_up').limit(5)\n",
    "\n",
    "# Convertire il DataFrame Spark in un DataFrame Pandas\n",
    "pandas_df = limited_df.toPandas()\n",
    "\n",
    "# Impostare l'opzione per consentire operazioni su frame di dati diversi\n",
    "spark.conf.set('spark.sql.compute.ops_on_diff_frames', 'true')\n",
    "\n",
    "# Creare un DataFrame Spark con recensioni utili basate sul valore del quantile\n",
    "useful_reviews_df = spark_df.filter(col('votes_up') >= votes_up_for_useful_review)\n",
    "\n",
    "# Campionamento di un sottoinsieme di recensioni non utili basato sulla proporzione\n",
    "not_useful_reviews_df = spark_df.filter(col('votes_up') < votes_up_for_useful_review).sample(fraction=(useful_reviews_df.count() / spark_df.count()), seed=0)\n",
    "\n",
    "# Reimpostare l'opzione per le operazioni su frame di dati diversi\n",
    "spark.conf.unset('spark.sql.compute.ops_on_diff_frames')\n",
    "\n",
    "# Unire i DataFrame di recensioni utili e non utili\n",
    "restricted_df = useful_reviews_df.union(not_useful_reviews_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T11:01:22.523571Z",
     "start_time": "2023-06-21T11:01:19.131829Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5550,
     "status": "ok",
     "timestamp": 1687342747184,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "CQ0xoEymUpjj",
    "outputId": "88b31895-3197-40f7-cf0e-48cecdcf9889"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/21 13:01:19 WARN TaskSetManager: Stage 18 contains a task of very large size (4301 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  votes_up  useful\n",
      "0  I've never written a review before for anythin...       167       1\n",
      "1  ---{Graphics}---\\r\\n☐ You forget what reality ...       395       1\n",
      "2  I was so hopeful that this game had turned aro...        60       1\n",
      "3  I've been playing No Mans Sky again to get the...       104       1\n",
      "4  [url=https://i.imgur.com/SScxDZS.png] No Man's...        31       1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# Definizione della funzione UDF per assegnare l'etichetta di output\n",
    "udf_y = udf(lambda x: 0 if x < votes_up_for_useful_review else 1, IntegerType())\n",
    "\n",
    "# Aggiunta della colonna 'useful' al DataFrame Spark\n",
    "restricted_df = restricted_df.withColumn('useful', udf_y(col('votes_up')))\n",
    "\n",
    "# Conversione del DataFrame Spark in un DataFrame Pandas on Spark\n",
    "restricted_df = restricted_df.limit(5).toPandas()\n",
    "\n",
    "# Stampa delle colonne 'review', 'votes_up' e 'useful' del DataFrame\n",
    "print(restricted_df[['review', 'votes_up', 'useful']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yR5RZV0RWY3M"
   },
   "source": [
    "# Obtain the Bag-Of-Words and predict, using the review text, the votes_up categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T11:01:28.791281Z",
     "start_time": "2023-06-21T11:01:28.685037Z"
    },
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1687342751574,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "LjnlhUwaYYQB"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convertire il DataFrame in un DataFrame Spark\n",
    "restricted_df = spark.createDataFrame(restricted_df)\n",
    "\n",
    "# Remove not characters (and \\n) in written reviews and transform the text into lowercase\n",
    "def clean(input):\n",
    "    import re\n",
    "    return ''.join(list(filter(lambda ele: re.search(\"[a-zA-Z\\s]+\", ele) is not None, list(re.sub('\\n', ' ', input.lower())))))\n",
    "\n",
    "# Creare una funzione UDF per applicare la pulizia del testo\n",
    "udf_remove_not_characters = udf(lambda x: clean(x), StringType())\n",
    "\n",
    "# Applicare la pulizia del testo direttamente sulla colonna 'review'\n",
    "clean_df = restricted_df.withColumn('cleaned_review', udf_remove_not_characters(col('review')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T11:01:32.544305Z",
     "start_time": "2023-06-21T11:01:31.833629Z"
    },
    "executionInfo": {
     "elapsed": 1851,
     "status": "ok",
     "timestamp": 1687342755609,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "lJpF795CYaWf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/21 13:01:32 WARN StopWordsRemover: Default locale set was [en_IT]; however, it was not found in available locales in JVM, falling back to en_US locale. Set param `locale` in order to respect another locale.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.sql.functions import col, size\n",
    "\n",
    "# Tokenization - break review text into list of its individual terms (words in this case)\n",
    "tokenizer = Tokenizer(inputCol='cleaned_review', outputCol='review_words')\n",
    "wordsData = tokenizer.transform(clean_df)\n",
    "\n",
    "# Remove review having no words after filtering\n",
    "wordsData = wordsData.filter(size(col('review_words')) > 0)\n",
    "\n",
    "# Removing StopWords\n",
    "remover = StopWordsRemover(inputCol='review_words', outputCol='no_stop_words')\n",
    "filteredData = remover.transform(wordsData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T11:01:54.538639Z",
     "start_time": "2023-06-21T11:01:51.420228Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "executionInfo": {
     "elapsed": 1403,
     "status": "error",
     "timestamp": 1687342990627,
     "user": {
      "displayName": "Ilaria De Sio",
      "userId": "04931593397008720475"
     },
     "user_tz": -120
    },
    "id": "jdKB7PtrZbt_",
    "outputId": "48faf4ab-3668-4ef0-9780-35128de9ac0e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package snowball_data to\n",
      "[nltk_data]     /Users/ilariadesio/nltk_data...\n",
      "[nltk_data]   Package snowball_data is already up-to-date!\n",
      "[Stage 19:=====================>                                    (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/21 13:01:52 ERROR Executor: Exception in task 4.0 in stage 19.0 (TID 62)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/var/folders/pt/3cv5yjcs1rv1hdw6xwxdchz00000gn/T/ipykernel_81464/2365613367.py\", line 10, in <lambda>\n",
      "  File \"/var/folders/pt/3cv5yjcs1rv1hdw6xwxdchz00000gn/T/ipykernel_81464/2365613367.py\", line 7, in clean\n",
      "  File \"/Users/ilariadesio/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 4915, in filter\n",
      "    return _invoke_higher_order_function(\"ArrayFilter\", [col], [f])\n",
      "  File \"/Users/ilariadesio/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 4715, in _invoke_higher_order_function\n",
      "    assert sc is not None and sc._jvm is not None\n",
      "AssertionError\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:559)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:512)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.ContextAwareIterator.hasNext(ContextAwareIterator.scala:39)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n",
      "\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.writeIteratorToStream(PythonUDFRunner.scala:53)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:438)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:272)\n",
      "23/06/21 13:01:52 ERROR Executor: Exception in task 1.0 in stage 19.0 (TID 59)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/var/folders/pt/3cv5yjcs1rv1hdw6xwxdchz00000gn/T/ipykernel_81464/2365613367.py\", line 10, in <lambda>\n",
      "  File \"/var/folders/pt/3cv5yjcs1rv1hdw6xwxdchz00000gn/T/ipykernel_81464/2365613367.py\", line 7, in clean\n",
      "  File \"/Users/ilariadesio/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 4915, in filter\n",
      "    return _invoke_higher_order_function(\"ArrayFilter\", [col], [f])\n",
      "  File \"/Users/ilariadesio/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 4715, in _invoke_higher_order_function\n",
      "    assert sc is not None and sc._jvm is not None\n",
      "AssertionError\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:559)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:512)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.ContextAwareIterator.hasNext(ContextAwareIterator.scala:39)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n",
      "\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.writeIteratorToStream(PythonUDFRunner.scala:53)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:438)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:272)\n",
      "23/06/21 13:01:52 ERROR Executor: Exception in task 6.0 in stage 19.0 (TID 64)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/var/folders/pt/3cv5yjcs1rv1hdw6xwxdchz00000gn/T/ipykernel_81464/2365613367.py\", line 10, in <lambda>\n",
      "  File \"/var/folders/pt/3cv5yjcs1rv1hdw6xwxdchz00000gn/T/ipykernel_81464/2365613367.py\", line 7, in clean\n",
      "  File \"/Users/ilariadesio/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 4915, in filter\n",
      "    return _invoke_higher_order_function(\"ArrayFilter\", [col], [f])\n",
      "  File \"/Users/ilariadesio/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 4715, in _invoke_higher_order_function\n",
      "    assert sc is not None and sc._jvm is not None\n",
      "AssertionError\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:559)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:512)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.ContextAwareIterator.hasNext(ContextAwareIterator.scala:39)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n",
      "\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.writeIteratorToStream(PythonUDFRunner.scala:53)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:438)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:272)\n",
      "23/06/21 13:01:52 ERROR Executor: Exception in task 3.0 in stage 19.0 (TID 61)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/var/folders/pt/3cv5yjcs1rv1hdw6xwxdchz00000gn/T/ipykernel_81464/2365613367.py\", line 10, in <lambda>\n",
      "  File \"/var/folders/pt/3cv5yjcs1rv1hdw6xwxdchz00000gn/T/ipykernel_81464/2365613367.py\", line 7, in clean\n",
      "  File \"/Users/ilariadesio/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 4915, in filter\n",
      "    return _invoke_higher_order_function(\"ArrayFilter\", [col], [f])\n",
      "  File \"/Users/ilariadesio/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 4715, in _invoke_higher_order_function\n",
      "    assert sc is not None and sc._jvm is not None\n",
      "AssertionError\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:559)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:512)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.ContextAwareIterator.hasNext(ContextAwareIterator.scala:39)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n",
      "\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.writeIteratorToStream(PythonUDFRunner.scala:53)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:438)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:272)\n",
      "23/06/21 13:01:52 ERROR Executor: Exception in task 7.0 in stage 19.0 (TID 65)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/var/folders/pt/3cv5yjcs1rv1hdw6xwxdchz00000gn/T/ipykernel_81464/2365613367.py\", line 10, in <lambda>\n",
      "  File \"/var/folders/pt/3cv5yjcs1rv1hdw6xwxdchz00000gn/T/ipykernel_81464/2365613367.py\", line 7, in clean\n",
      "  File \"/Users/ilariadesio/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 4915, in filter\n",
      "    return _invoke_higher_order_function(\"ArrayFilter\", [col], [f])\n",
      "  File \"/Users/ilariadesio/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 4715, in _invoke_higher_order_function\n",
      "    assert sc is not None and sc._jvm is not None\n",
      "AssertionError\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:559)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:512)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.ContextAwareIterator.hasNext(ContextAwareIterator.scala:39)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n",
      "\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.writeIteratorToStream(PythonUDFRunner.scala:53)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:438)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:272)\n",
      "23/06/21 13:01:52 WARN TaskSetManager: Lost task 4.0 in stage 19.0 (TID 62) (mbp-di-ilaria-2.lan executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/var/folders/pt/3cv5yjcs1rv1hdw6xwxdchz00000gn/T/ipykernel_81464/2365613367.py\", line 10, in <lambda>\n",
      "  File \"/var/folders/pt/3cv5yjcs1rv1hdw6xwxdchz00000gn/T/ipykernel_81464/2365613367.py\", line 7, in clean\n",
      "  File \"/Users/ilariadesio/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 4915, in filter\n",
      "    return _invoke_higher_order_function(\"ArrayFilter\", [col], [f])\n",
      "  File \"/Users/ilariadesio/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 4715, in _invoke_higher_order_function\n",
      "    assert sc is not None and sc._jvm is not None\n",
      "AssertionError\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:559)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:512)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.ContextAwareIterator.hasNext(ContextAwareIterator.scala:39)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n",
      "\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.writeIteratorToStream(PythonUDFRunner.scala:53)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:438)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:272)\n",
      "\n",
      "23/06/21 13:01:52 ERROR TaskSetManager: Task 4 in stage 19.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/var/folders/pt/3cv5yjcs1rv1hdw6xwxdchz00000gn/T/ipykernel_81464/2365613367.py\", line 10, in <lambda>\n  File \"/var/folders/pt/3cv5yjcs1rv1hdw6xwxdchz00000gn/T/ipykernel_81464/2365613367.py\", line 7, in clean\n  File \"/Users/ilariadesio/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 4915, in filter\n    return _invoke_higher_order_function(\"ArrayFilter\", [col], [f])\n  File \"/Users/ilariadesio/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 4715, in _invoke_higher_order_function\n    assert sc is not None and sc._jvm is not None\nAssertionError\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pt/3cv5yjcs1rv1hdw6xwxdchz00000gn/T/ipykernel_81464/2887160937.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Applicazione di CountVectorizer: converte la lista di token in un vettore di conteggi di token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'no_stop_words'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'BoW'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstemmed_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mfeaturizedData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstemmed_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             raise TypeError(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/var/folders/pt/3cv5yjcs1rv1hdw6xwxdchz00000gn/T/ipykernel_81464/2365613367.py\", line 10, in <lambda>\n  File \"/var/folders/pt/3cv5yjcs1rv1hdw6xwxdchz00000gn/T/ipykernel_81464/2365613367.py\", line 7, in clean\n  File \"/Users/ilariadesio/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 4915, in filter\n    return _invoke_higher_order_function(\"ArrayFilter\", [col], [f])\n  File \"/Users/ilariadesio/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 4715, in _invoke_higher_order_function\n    assert sc is not None and sc._jvm is not None\nAssertionError\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "import nltk\n",
    "nltk.download('snowball_data')\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ProjectBigData\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Applicazione della stemmatizzazione\n",
    "stemmer = nltk.stem.SnowballStemmer('english')\n",
    "udf_stemming = udf(lambda tokens: [stemmer.stem(token) for token in tokens], ArrayType(StringType()))\n",
    "stemmed_df = filteredData.withColumn('stemmed_review', udf_stemming(col('no_stop_words')))\n",
    "\n",
    "# Applicazione di CountVectorizer: converte la lista di token in un vettore di conteggi di token\n",
    "count = CountVectorizer(inputCol='no_stop_words', outputCol='BoW')\n",
    "model = count.fit(stemmed_df)\n",
    "featurizedData = model.transform(stemmed_df)\n",
    "\n",
    "featurizedData[['review', 'cleaned_review', 'review_words', 'no_stop_words', 'stemmed_review', 'BoW', 'votes_up', 'useful']].limit(5).toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Weather_forecasting_pyspark",
   "notebookOrigID": 1252952709241176,
   "widgets": {}
  },
  "colab": {
   "collapsed_sections": [
    "mw8uGOrDggaB",
    "y2DcATuHj3wl",
    "-YKjcPjPdAgU",
    "34eeT8mlsWvs",
    "GaWehUy1a-ox",
    "FGXW-f_I6lS4",
    "tfwE40zfTKdD",
    "ZjZK02GF-KMg",
    "mN_zvztdoz4u",
    "IEoJPC2jUlga",
    "Me7LtqZluFII"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
